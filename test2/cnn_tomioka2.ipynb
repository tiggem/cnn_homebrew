{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8KoKsfiAK9JY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from common.layers import softmax, Convolution, MaxPooling, ReLU, Affine, SoftmaxWithLoss\n",
    "from common.optimizer import RMSProp, Adam\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0qKXumefK9Jb"
   },
   "outputs": [],
   "source": [
    "class cnn_homebrew:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':1, 'stride':1},\n",
    "                 pool_param={'pool_size':2, 'pad':0, 'stride':2},\n",
    "                 hidden_size=100, output_size=15, weight_init_std=0.01,\n",
    "                batch_size=500):\n",
    "        \"\"\"\n",
    "        input_size : tuple, 入力の配列形状(チャンネル数、画像の高さ、画像の幅)\n",
    "        conv_param : dict, 畳み込みの条件\n",
    "        pool_param : dict, プーリングの条件\n",
    "        hidden_size : int, 隠れ層のノード数\n",
    "        output_size : int, 出力層のノード数\n",
    "        weight_init_std ： float, 重みWを初期化する際に用いる標準偏差\n",
    "        \"\"\"\n",
    "                \n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        \n",
    "        pool_size = pool_param['pool_size']\n",
    "        pool_pad = pool_param['pad']\n",
    "        pool_stride = pool_param['stride']\n",
    "        \n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size + 2*filter_pad - filter_size) // filter_stride + 1 # 畳み込み後のサイズ(H,W共通)\n",
    "        pool_output_size = (conv_output_size + 2*pool_pad - pool_size) // pool_stride + 1 # プーリング後のサイズ(H,W共通)\n",
    "        pool_output_pixel = filter_num * pool_output_size * pool_output_size # プーリング後のピクセル総数\n",
    "        \n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        std = weight_init_std\n",
    "        self.batch_size = batch_size\n",
    "        self.params['W1'] = std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size) # W1は畳み込みフィルターの重みになる\n",
    "        self.params['b1'] = np.zeros(filter_num) #b1は畳み込みフィルターのバイアスになる\n",
    "        self.params['W2'] = std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size) # W1は畳み込みフィルターの重みになる\n",
    "        self.params['b2'] = np.zeros(filter_num) \n",
    "        self.params['W3'] = std *  np.random.randn(pool_output_pixel, hidden_size)\n",
    "        self.params['b3'] = np.zeros(hidden_size)\n",
    "        self.params['W4'] = std *  np.random.randn(hidden_size, output_size)\n",
    "        self.params['b4'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad']) # W1が畳み込みフィルターの重み, b1が畳み込みフィルターのバイアスになる\n",
    "        self.layers['ReLU1'] = ReLU()\n",
    "        self.layers['Pool1'] = MaxPooling(pool_h=pool_size, pool_w=pool_size, stride=pool_stride, pad=pool_pad)\n",
    "        \n",
    "        self.layers['Conv2'] = Convolution(self.params['W2'], self.params['b2'],\n",
    "                                           conv_param['stride'], conv_param['pad']) # W1が畳み込みフィルターの重み, b1が畳み込みフィルターのバイアスになる\n",
    "        self.layers['ReLU2'] = ReLU()\n",
    "        self.layers['Pool2'] = MaxPooling(pool_h=pool_size, pool_w=pool_size, stride=pool_stride, pad=pool_pad)\n",
    "        \n",
    "        self.layers['Affine1'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        self.layers['ReLU3'] = ReLU()\n",
    "        self.layers['Affine2'] = Affine(self.params['W4'], self.params['b4'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"\n",
    "        損失関数\n",
    "        x : 入力データ\n",
    "        t : 教師データ\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / self.batch_size)):\n",
    "            tx = x[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            tt = t[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝播法）\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師データ\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Conv2'].dW, self.layers['Conv2'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W4'], grads['b4'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cf4FRA_zK9Jd",
    "outputId": "ac863dc9-2d17-4ccb-8611-2fab6cf3f269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape= (3000, 1, 28, 28)\n",
      "train_label.shape= (3000, 15)\n",
      "X_train.shape= (2100, 784)\n",
      "y_train.shape= (2100, 15)\n",
      "X_test.shape= (900, 784)\n",
      "y_test.shape= (900, 15)\n"
     ]
    }
   ],
   "source": [
    "#データを読む\n",
    "train_data = np.load(\"../1_data/train_data.npy\")\n",
    "train_label = np.load(\"../1_data/train_label.npy\")\n",
    "print(\"train_data.shape=\", train_data.shape)\n",
    "print(\"train_label.shape=\", train_label.shape)\n",
    "\n",
    "# 正規化\n",
    "train_data = (train_data - train_data.min()) / train_data.max()\n",
    "train_data = train_data.astype('float32')\n",
    "\n",
    "train_data = train_data.reshape(-1, 28*28)\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, \n",
    "                                                    test_size=0.3, random_state=1234,\n",
    "                                                    shuffle=True)\n",
    "print('X_train.shape=', X_train.shape)\n",
    "print('y_train.shape=',y_train.shape)\n",
    "print('X_test.shape=', X_test.shape)\n",
    "print('y_test.shape=',y_test.shape)\n",
    "\n",
    "# train = X_train/255\n",
    "# test = X_test/255\n",
    "# train = train.reshape(-1, 1, 28*28)\n",
    "# test = test.reshape(-1, 1, 28*28)\n",
    "# print(train.shape)\n",
    "# 正規化\n",
    "# train = (train - train.min()) / train.max()\n",
    "# train = train.astype('float32')\n",
    "\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# lb = LabelBinarizer()\n",
    "# train_labels = lb.fit_transform(y_train)\n",
    "# test_labels = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iFG8-RQ0K9Jf"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,1,28,28)\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "QTzLJsA0K9Jf",
    "outputId": "29d3bfe6-da0d-4f89-de5e-a32a06f7cbb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (12800,750) and (25,30) not aligned: 750 (dim 1) != 25 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-572bd1b1108d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# 勾配の計算 (誤差逆伝播法を用いる)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m# 更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8e1ecaabc3c8>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8e1ecaabc3c8>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m教師データ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8e1ecaabc3c8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skillupAI/Deep Learning/DAY1-2/DAY1_vr6_0_0/4_kadai/test/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# 行列の積を計算し、バイアスを足す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_W\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# 画像形式に戻して、チャンネルの軸を2番目に移動させる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (12800,750) and (25,30) not aligned: 750 (dim 1) != 25 (dim 0)"
     ]
    }
   ],
   "source": [
    "x = X_train[:2000,:] #15000, epoch=1,0.76. 20000,18000はできない．\n",
    "t = y_train[:2000,:]\n",
    "\n",
    "x = x.reshape(-1,1,28,28) # 配列形式の変形\n",
    "\n",
    "epochs = 5 #27\n",
    "batch_size = 200 #500\n",
    "\n",
    "#optimizer = RMSProp(lr=0.01, rho=0.9)\n",
    "optimizer = Adam(lr=0.01, beta1=0.9, beta2=0.999)\n",
    "\n",
    "# 繰り返し回数\n",
    "xsize = x.shape[0]\n",
    "\n",
    "iter_num = np.ceil(xsize / batch_size).astype('int')\n",
    "\n",
    "\n",
    "# CNNのオブジェクト生成\n",
    "model = cnn_homebrew(input_dim=(1, 28, 28), \n",
    "                     conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                     pool_param={'pool_size':2, 'pad':0, 'stride':2},\n",
    "                     hidden_size=500, output_size=15, weight_init_std=0.01,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch=%s\"%epoch)\n",
    "\n",
    "    # シャッフル\n",
    "    idx = np.arange(xsize)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    for it in range(iter_num):\n",
    "        \"\"\"\n",
    "        ランダムなミニバッチを順番に取り出す\n",
    "        \"\"\"\n",
    "        #print(\"it=\", it)\n",
    "        mask = idx[batch_size*it : batch_size*(it+1)]\n",
    "\n",
    "        # ミニバッチの生成\n",
    "        x_train = x[mask]\n",
    "        t_train = t[mask]\n",
    "        \n",
    "        # 勾配の計算 (誤差逆伝播法を用いる) \n",
    "        grads = model.gradient(x_train, t_train)\n",
    "        # 更新\n",
    "        optimizer.update(model.params, grads)\n",
    "\n",
    "    ## 学習経過の記録\n",
    "\n",
    "    # 訓練データにおけるloss\n",
    "#     print(\"calculating train_loss\") \n",
    "    train_loss.append(model.loss(x,  t))\n",
    "\n",
    "#     print(\"calculating test_loss\")\n",
    "    # テストデータにおけるloss\n",
    "    print(\"tl%s\"%epoch)\n",
    "    test_loss.append(model.loss(X_test, y_test))\n",
    "    print(f\"test_loss,{test_loss[epoch]}\")\n",
    "#     print(\"calculating train_accuracy\")\n",
    "    # 訓練データにて精度を確認\n",
    "    train_accuracy.append(model.accuracy(x, t))\n",
    "          \n",
    "#     print(\"calculating test_accuracy\")\n",
    "    # テストデータにて精度を算出\n",
    "    print(\"ta%s\"%epoch)\n",
    "    test_accuracy.append(model.accuracy(X_test, y_test))\n",
    "    print(f\"test_acc,{test_accuracy[epoch]}\")\n",
    "    if test_accuracy[epoch]>=0.98 and test_loss[epoch]<0.001:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "O8YUbuxxK9Jj",
    "outputId": "158acd2e-c7d3-4146-e97b-1cd1f9673cc7"
   },
   "outputs": [],
   "source": [
    "# lossとaccuracyのグラフ化\n",
    "df_log = pd.DataFrame({\"train_loss\":train_loss,\n",
    "             \"test_loss\":test_loss,\n",
    "             \"train_accuracy\":train_accuracy,\n",
    "             \"test_accuracy\":test_accuracy})\n",
    "\n",
    "df_log.plot(style=['r-', 'r--', 'b-', 'b--'])\n",
    "plt.ylim([0,4])\n",
    "plt.ylabel(\"Accuracy or loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "KPnuh2z0K9Jj",
    "outputId": "4cbfe132-4a3e-4132-e9a3-3574e467724a"
   },
   "outputs": [],
   "source": [
    "あ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,0.030907047067291988\n",
    "test_acc,0.9869907407407408\n",
    "epoch=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rYgLodEK9Jk"
   },
   "outputs": [],
   "source": [
    "with open('katakana_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVCJ-ac6vxpw"
   },
   "outputs": [],
   "source": [
    "with open('model_params.pickle', 'wb') as f:\n",
    "    pickle.dump(model.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUM2CJKZK9Jk"
   },
   "outputs": [],
   "source": [
    "あ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Id94MIloK9Jl"
   },
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    with open('katakana_model.pickle', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "notwork = init_network()\n",
    "print(network.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQwhqiOsK9Jl"
   },
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "network = init_network()\n",
    "print(network.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n686rN4DK9Jl"
   },
   "outputs": [],
   "source": [
    "model = TwoLayerNet(input_size=28*28, hidden_size=10, output_size=15)\n",
    "    with open(\"params.pickle\", \"rb\") as f:\n",
    "        params = pickle.load(f)\n",
    "        for i, key in enumerate(['Affine1', 'Affine2']):\n",
    "            model.layers[key].W = params['W' + str(i+1)]\n",
    "            model.layers[key].b = params['b' + str(i+1)]\n",
    "            model.params[key].W = params['W' + str(i+1)]\n",
    "            model.params[key].b = params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3qSVf-_K9Jl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpr7IjBDK9Jm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fz4lXa2wK9Jm"
   },
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "for i in range(3):\n",
    "    print(i,a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRp3p0JrK9Jm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
